<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Scanner Emocional - √Ålibis Digital</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tailwindcss/2.2.19/tailwind.min.css">
  <script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tracking.js/1.1.3/tracking-min.js"></script>
  <style>
    body { background: linear-gradient(180deg, #0b1120 0%, #1e293b 100%); }
    #particles-js { position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: -1; }
    #particles-fallback { display: none; text-align: center; color: #fff; padding: 20px; }
    .holo-nav { background: rgba(11, 17, 32, 0.8); backdrop-filter: blur(10px); }
    .holo-nav.active { box-shadow: 0 4px 15px rgba(34, 211, 238, 0.3); }
    .dropdown:hover .dropdown-menu { display: block; }
    .dropdown-menu { display: none; position: absolute; background: rgba(11, 17, 32, 0.9); backdrop-filter: blur(10px); padding: 10px; border-radius: 10px; top: 100%; left: 0; z-index: 50; }
    .dropdown-menu a { display: block; padding: 8px 12px; color: #fff; }
    .dropdown-menu-mobile a { display: block; padding: 8px 12px; color: #fff; text-align: center; }
    .futuristic-btn { background: linear-gradient(90deg, #22d3ee, #06b6d4); transition: all 0.3s; }
    .futuristic-btn:hover { transform: scale(1.05); box-shadow: 0 0 15px rgba(34, 211, 238, 0.5); }
    .shine { animation: shine 2s infinite; }
    @keyframes shine { 0% { box-shadow: 0 0 5px rgba(34, 211, 238, 0.5); } 50% { box-shadow: 0 0 20px rgba(34, 211, 238, 0.8); } 100% { box-shadow: 0 0 5px rgba(34, 211, 238, 0.5); } }
    .fade-in { opacity: 0; animation: fadeIn 1s forwards; }
    @keyframes fadeIn { 0% { opacity: 0; } 100% { opacity: 1; } }
    .slide-in-left { animation: slideInLeft 1s forwards; }
    @keyframes slideInLeft { 0% { transform: translateX(-20px); opacity: 0; } 100% { transform: translateX(0); opacity: 1; } }
    .slide-in-right { animation: slideInRight 1s forwards; }
    @keyframes slideInRight { 0% { transform: translateX(20px); opacity: 0; } 100% { transform: translateX(0); opacity: 1; } }
    .animate-on-scroll { opacity: 0; transform: translateY(20px); transition: all 0.8s; }
    .animate-on-scroll.active { opacity: 1; transform: translateY(0); }
    .video-placeholder { display: none; width: 400px; height: 300px; background: #1e293b; border-radius: 12px; color: #fff; text-align: center; line-height: 300px; font-size: 1.2rem; border: 1px solid #22d3ee; }
    .hidden { display: none !important; }
    .neon-box { background: rgba(11, 17, 32, 0.8); border: 1px solid #22d3ee; border-radius: 12px; padding: 20px; box-shadow: 0 0 15px rgba(34, 211, 238, 0.3); }
    .ppg-overlay { display: none; position: absolute; top: 0; left: 0; width: 400px; height: 300px; background: rgba(0, 0, 0, 0.5); border-radius: 12px; }
    .ppg-overlay.active { display: flex; flex-direction: column; justify-content: center; align-items: center; }
    .ppg-stay-still { color: #fff; font-size: 1.5rem; margin-bottom: 10px; }
    .ppg-progress-container { width: 80%; height: 10px; background: #1e293b; border-radius: 5px; overflow: hidden; }
    .ppg-progress-bar { width: 0; height: 100%; background: #22d3ee; transition: width 0.1s linear; }
    .mic-prompt { display: none; align-items: center; margin-top: 10px; color: #fff; }
    .mic-icon::before { content: "üéôÔ∏è"; margin-right: 8px; }
    .testimonial-card { background: rgba(11, 17, 32, 0.8); border: 1px solid #22d3ee; border-radius: 12px; padding: 15px; margin: 10px; width: 300px; }
    .testimonial-img { width: 60px; height: 60px; border-radius: 50%; margin-right: 15px; }
    #chat-container { position: fixed; bottom: 20px; right: 20px; z-index: 100; }
    #chat-bubble { background: linear-gradient(90deg, #22d3ee, #06b6d4); width: 60px; height: 60px; border-radius: 50%; display: flex; justify-content: center; align-items: center; cursor: pointer; box-shadow: 0 0 15px rgba(34, 211, 238, 0.5); }
    #chat-window { display: none; position: absolute; bottom: 80px; right: 0; width: 300px; background: rgba(11, 17, 32, 0.9); backdrop-filter: blur(10px); border: 1px solid #22d3ee; border-radius: 12px; box-shadow: 0 0 15px rgba(34, 211, 238, 0.3); }
    #chat-messages { max-height: 300px; overflow-y: auto; padding: 15px; }
    #chat-input { background: #1e293b; border: 1px solid #22d3ee; border-radius: 20px; padding: 10px; color: #fff; }
    .listening-indicator { display: none; color: #22d3ee; margin-top: 5px; }
    .loading-dots::after { content: '.'; animation: dots 1.5s steps(3, end) infinite; }
    @keyframes dots { 0% { content: '.'; } 33% { content: '..'; } 66% { content: '...'; } 100% { content: '.'; } }
  </style>
</head>
<body class="bg-transparent text-white font-sans">
  <div id="particles-js"></div>
  <div id="particles-fallback">Particle effect failed to load. Please check your internet connection.</div>

  <header class="holo-nav fixed top-0 left-0 w-full z-50 transition-shadow duration-300">
    <div class="max-w-7xl mx-auto px-6 py-4 flex justify-between items-center">
      <div class="flex items-center">
        <a href="/index.html" aria-label="P√°gina inicial da √Ålibis Digital">
          <img src="/assets/logo.png" alt="Logo da √Ålibis Digital" class="h-10 w-auto" onerror="this.src='https://via.placeholder.com/100x40?text=Logo'; console.error('Erro ao carregar logo.png')">
        </a>
      </div>
      <div class="flex items-center">
        <div class="md:hidden">
          <button id="hamburger-menu" class="text-white focus:outline-none p-2 rounded" aria-label="Abrir menu de navega√ß√£o">
            <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16" />
            </svg>
          </button>
        </div>
        <div class="relative">
          <select id="language-selector" class="bg-transparent text-white border border-[#22d3ee] rounded-full px-3 py-1 focus:outline-none appearance-none" onchange="changeLanguage()">
            <option value="pt-BR">Portugu√™s</option>
            <option value="en">English</option>
            <option value="es">Espa√±ol</option>
          </select>
          <svg class="w-4 h-4 absolute right-2 top-1/2 transform -translate-y-1/2 text-white pointer-events-none" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
          </svg>
        </div>
      </div>
      <nav id="navbar" class="hidden md:flex space-x-6 text-sm items-center">
        <div class="dropdown relative">
          <button class="hover:text-[#22d3ee] transition flex items-center" aria-label="Abrir menu de servi√ßos">
            <svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 12h14M12 5l7 7-7 7"></path>
            </svg>
            <span>Servi√ßos</span>
            <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
            </svg>
          </button>
          <div class="dropdown-menu">
            <a href="/scanner.html" class="hover:text-[#22d3ee] transition">Scanner com IA</a>
            <a href="/apoio-emocional.html" class="hover:text-[#22d3ee] transition">Avalia√ß√£o Emocional</a>
            <a href="/medical-ai.html" class="hover:text-[#22d3ee] transition">Diagn√≥stico M√©dico</a>
            <a href="/alibi.html" class="hover:text-[#22d3ee] transition">Criar √Ålibi</a>
          </div>
        </div>
        <a href="/blog.html" class="hover:text-[#22d3ee] transition">Blog</a>
        <a href="/planos.html" class="hover:text-[#22d3ee] transition">Planos</a>
        <a href="/suporte.html" class="hover:text-[#22d3ee] transition">Suporte</a>
        <a href="/planos.html" class="futuristic-btn text-white py-2 px-4 rounded-full text-sm font-semibold" aria-label="Teste Gr√°tis">üîç Teste Gr√°tis</a>
      </nav>
    </div>
    <div id="mobile-menu" class="md:hidden bg-gray-800 bg-opacity-95 w-full hidden py-4">
      <nav class="flex flex-col items-center space-y-4">
        <div class="w-full">
          <button id="services-toggle" class="text-white py-2 px-4 text-lg w-full text-center hover:bg-gray-700 rounded flex justify-between items-center">
            <span>Servi√ßos</span>
            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
            </svg>
          </button>
          <div id="services-menu" class="dropdown-menu-mobile hidden">
            <a href="/scanner.html" class="hover:bg-gray-700">Scanner com IA</a>
            <a href="/apoio-emocional.html" class="hover:bg-gray-700">Avalia√ß√£o Emocional</a>
            <a href="/medical-ai.html" class="hover:bg-gray-700">Diagn√≥stico M√©dico</a>
            <a href="/alibi.html" class="hover:bg-gray-700">Criar √Ålibi</a>
          </div>
        </div>
        <a href="/blog.html" class="text-white py-2 px-4 text-lg w-full text-center hover:bg-gray-700 rounded">Blog</a>
        <a href="/planos.html" class="text-white py-2 px-4 text-lg w-full text-center hover:bg-gray-700 rounded">Planos</a>
        <a href="/suporte.html" class="text-white py-2 px-4 text-lg w-full text-center hover:bg-gray-700 rounded">Suporte</a>
        <a href="/planos.html" class="futuristic-btn text-white py-2 px-4 rounded-full text-lg w-full text-center" aria-label="Teste Gr√°tis">üîç Teste Gr√°tis</a>
      </nav>
    </div>
  </header>
  <div class="h-20"></div>

  <section id="hero" class="text-white text-center py-20 px-6 relative animate-on-scroll">
    <div class="max-w-6xl mx-auto">
      <h1 class="text-5xl md:text-6xl font-serif font-bold mb-6 leading-tight fade-in">Transforme Sua Vida com o Scanner Emocional</h1>
      <p class="text-lg md:text-xl text-gray-300 mb-10 fade-in">Descubra seu estado emocional com IA avan√ßada. Teste gr√°tis agora!</p>
      <div>
        <a href="/relatorios-avancados.html" class="futuristic-btn text-white font-bold py-3 px-8 rounded-full" aria-label="Obter Relat√≥rios Avan√ßados">üîç Obter Relat√≥rios Avan√ßados</a>
      </div>
    </div>
  </section>

  <section class="py-10 px-6 text-center animate-on-scroll" id="emotion-intro">
    <div class="max-w-4xl mx-auto">
      <h2 class="text-3xl font-bold mb-6 text-white shine">Entenda Suas Emo√ß√µes</h2>
      <p class="text-lg mb-6 text-gray-300 fade-in">Nosso scanner analisa express√µes faciais, frequ√™ncia card√≠aca e tom de voz para identificar emo√ß√µes como felicidade, tristeza, raiva, medo, surpresa, nojo e neutralidade. Cada emo√ß√£o reflete um estado interno √∫nico, ajudando voc√™ a se conhecer melhor.</p>
      <ul class="text-left text-gray-300 space-y-2 fade-in">
        <li><strong>Felicidade:</strong> Sorrisos largos, olhos brilhantes e tom animado indicam alegria e bem-estar.</li>
        <li><strong>Tristeza:</strong> Sobrancelhas ca√≠das, boca curvada e voz baixa sugerem melancolia ou introspec√ß√£o.</li>
        <li><strong>Raiva:</strong> Sobrancelhas franzidas, l√°bios apertados e tom elevado mostram tens√£o ou frustra√ß√£o.</li>
        <li><strong>Medo:</strong> Olhos arregalados, boca entreaberta e voz tr√™mula refletem ansiedade ou incerteza.</li>
        <li><strong>Surpresa:</strong> Sobrancelhas erguidas, olhos abertos e tom agudo indicam algo inesperado.</li>
        <li><strong>Nojo:</strong> Nariz enrugado, l√°bios contra√≠dos e tom de repulsa mostram desagrado.</li>
        <li><strong>Neutralidade:</strong> Express√£o relaxada e tom est√°vel podem indicar calma ou concentra√ß√£o.</li>
      </ul>
      <button onclick="document.getElementById('scanner').scrollIntoView({behavior: 'smooth'})" class="futuristic-btn text-white font-bold py-2 px-6 rounded-full text-sm shine mt-6" aria-label="Come√ßar o Scanner">Come√ßar o Scanner</button>
    </div>
  </section>

  <section class="py-10 px-6 text-center animate-on-scroll scanner-container" id="scanner">
    <h2 class="text-4xl font-bold mb-6 text-white shine">Seu rosto carrega sinais. Vamos descobrir o que ele diz?</h2>
    <p class="text-lg mb-8 text-gray-300 fade-in">Ative sua c√¢mera e permita acesso a dados biom√©tricos (frequ√™ncia card√≠aca, tom de voz) para um diagn√≥stico emocional detalhado com idade aparente.</p>
    <div class="flex flex-col items-center mb-4 relative">
      <video id="video" width="400" height="300" autoplay class="rounded-xl shadow-md border border-[#22d3ee]" aria-label="V√≠deo da c√¢mera para an√°lise emocional"></video>
      <div id="ppg-overlay" class="ppg-overlay">
        <span class="ppg-stay-still">Fique parado</span>
        <div class="ppg-progress-container">
          <div id="ppg-progress-bar" class="ppg-progress-bar"></div>
        </div>
      </div>
      <div id="video-placeholder" class="video-placeholder">C√¢mera n√£o dispon√≠vel</div>
      <div id="mic-prompt" class="mic-prompt" style="display: none;">
        <span class="mic-icon"></span>
        <span>Leia esta frase: "Estou me sentindo bem hoje"</span>
      </div>
      <div id="speech-output" class="mt-2 text-gray-300 text-lg"></div>
      <div id="vr-toggle" class="mt-4">
        <button onclick="toggleVR()" class="futuristic-btn text-white font-bold py-2 px-6 rounded-full text-sm shine" aria-label="Ativar Relaxamento VR/AR">Ativar Relaxamento VR/AR</button>
      </div>
    </div>
    <div class="flex justify-center mb-4">
      <button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold py-2 px-6 rounded-full text-sm shine" aria-label="Analisar Estado Emocional">Analisar Estado Emocional</button>
      <button onclick="initMedicalConsult()" class="futuristic-btn text-white font-bold py-2 px-6 rounded-full text-sm shine ml-4" aria-label="Consultar M√©dico">Consultar M√©dico</button>
    </div>
    <div id="scanner-result" class="neon-box mt-6" style="display: none;"></div>
    <div class="testimonials mt-8 max-w-4xl mx-auto">
      <h3 class="text-2xl font-bold mb-4 text-white shine">O que nossos usu√°rios dizem</h3>
      <div class="flex flex-wrap justify-center">
        <div class="testimonial-card flex items-center">
          <img src="https://via.placeholder.com/60" alt="Foto de Ana" class="testimonial-img">
          <div>
            <p class="text-gray-300">"O Scanner mudou minha vida! Descobri o que me estressava e agora vivo mais leve."</p>
            <p class="text-sm text-gray-400 mt-2">- Ana, 34 anos</p>
          </div>
        </div>
        <div class="testimonial-card flex items-center">
          <img src="https://via.placeholder.com/60" alt="Foto de Jo√£o" class="testimonial-img">
          <div>
            <p class="text-gray-300">"Incr√≠vel como a IA me ajudou a entender minhas emo√ß√µes. Recomendo!"</p>
            <p class="text-sm text-gray-400 mt-2">- Jo√£o, 29 anos</p>
          </div>
        </div>
      </div>
    </div>
    <div id="vr-container" style="display: none;"></div>
    <canvas id="canvas" width="400" height="300" style="display: none;"></canvas>
  </section>

  <div id="chat-container">
    <div id="chat-bubble">
      <svg xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 text-white" fill="none" viewBox="0 0 24 24" stroke="currentColor">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z" />
      </svg>
    </div>
    <div id="chat-window">
      <div id="chat-messages"></div>
      <div class="p-4">
        <input id="chat-input" type="text" class="w-full" placeholder="Digite ou fale sua mensagem" aria-label="Digite ou fale sua mensagem">
        <div id="listening-indicator" class="listening-indicator">üéôÔ∏è Ouvindo...</div>
      </div>
    </div>
  </div>

  <footer class="bg-[rgba(11,17,32,0.8)] text-gray-400 py-12 animate-on-scroll">
    <div class="max-w-6xl mx-auto px-6 grid grid-cols-1 md:grid-cols-3 gap-10 text-sm">
      <div class="slide-in-left">
        <h3 class="text-white text-2xl font-bold mb-4 shine">√Ålibis Digital</h3>
        <p class="fade-in">Solu√ß√µes de bem-estar com tecnologia avan√ßada.</p>
      </div>
      <div class="fade-in">
        <h4 class="text-white font-semibold mb-4">Navegue</h4>
        <ul class="space-y-2">
          <li><a href="/index.html" class="hover:text-white transition">In√≠cio</a></li>
          <li><a href="/scanner.html" class="hover:text-white transition">Scanner</a></li>
          <li><a href="/blog.html" class="hover:text-white transition">Blog</a></li>
          <li><a href="/medical-ai.html" class="hover:text-white transition">Diagn√≥stico M√©dico</a></li>
          <li><a href="/apoio-emocional.html" class="hover:text-white transition">Avalia√ß√£o Emocional</a></li>
          <li><a href="/alibi.html" class="hover:text-white transition">Criar √Ålibi</a></li>
          <li><a href="/planos.html" class="hover:text-white transition">Planos</a></li>
          <li><a href="/suporte.html" class="hover:text-white transition">Suporte</a></li>
          <li><a href="/politica-privacidade.html" class="hover:text-white transition">Privacidade</a></li>
        </ul>
      </div>
      <div class="slide-in-right">
        <h4 class="text-white font-semibold mb-4">Contato</h4>
        <ul class="space-y-2">
          <li class="fade-in">E-mail: contato@alibisdigital.com</li>
          <li class="fade-in">WhatsApp: (11) 91234-5678</li>
        </ul>
      </div>
    </div>
    <div class="text-center mt-8">
      <p class="text-sm">¬© 2025 √Ålibis Digital. Todos os direitos reservados.</p>
    </div>
  </footer>

  <script>
    console.log('Loading scanner.html at', new Date().toISOString());

    function initializeParticles() {
      if (typeof particlesJS !== 'undefined') {
        particlesJS('particles-js', {
          particles: {
            number: { value: 100, density: { enable: true, value_area: 800 } },
            color: { value: '#22d3ee' },
            shape: { type: 'circle' },
            opacity: { value: 0.7, random: true },
            size: { value: 3, random: true },
            line_linked: {
              enable: true,
              distance: 120,
              color: '#22d3ee',
              opacity: 0.4,
              width: 1
            },
            move: { speed: 1, direction: 'none', random: true }
          },
          interactivity: {
            detect_on: 'canvas',
            events: {
              onhover: { enable: true, mode: 'repulse' },
              onclick: { enable: true, mode: 'push' }
            }
          },
          retina_detect: true
        });
        console.log('Particles.js loaded successfully with hexagonal effect');
      } else {
        console.error('particlesJS not loaded - showing fallback');
        document.getElementById('particles-fallback').style.display = 'block';
      }
    }

    if (document.readyState === 'complete' || document.readyState === 'interactive') {
      initializeParticles();
    } else {
      window.addEventListener('DOMContentLoaded', initializeParticles);
    }

    if (window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
      particlesJS('particles-js', { particles: { number: { value: 0 } } });
      console.log('Reduced motion detected - particles disabled');
    }
  </script>

  <script>
    const apiKey = 'AmoIQKuEFggNsZmeO_Ur50ZZmfSrZ3mX';
    const apiSecret = 'WoRf3C8_IqQhe0Su8coFmOnAB_0nOheY';
    let diagnosisText = '';

    function generateDiagnosis(primaryEmotion, heartRate, age, isSimulated) {
      const emotionPortuguese = {
        sadness: 'tristeza',
        anger: 'raiva',
        happiness: 'felicidade',
        surprise: 'surpresa',
        neutral: 'neutra',
        fear: 'medo',
        disgust: 'nojo'
      };

      const primaryEmotionInPortuguese = emotionPortuguese[primaryEmotion] || primaryEmotion;
      const ageRangeMin = Math.max(18, age - 5);
      const ageRangeMax = age + 5;
      let diagnosis = '';
      let triggers = '';
      let suggestion = '';
      let personalizedPlan = '';
      let ctaButtons = '';

      switch (primaryEmotion) {
        case 'happiness':
          diagnosis = `Voc√™ est√° radiante, com uma frequ√™ncia card√≠aca de ${heartRate} bpm e tom de voz animado, refletindo felicidade e leveza.`;
          triggers = 'Pode ser resultado de uma conquista recente, uma conex√£o social significativa ou um momento de satisfa√ß√£o pessoal.';
          suggestion = 'Aproveite essa energia positiva para se conectar com amigos ou explorar uma atividade criativa.';
          personalizedPlan = 'Plano: 10 minutos de medita√ß√£o di√°ria e caminhada ao ar livre.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/planos.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Assinar Plano Premium</button></div>';
          break;
        case 'sadness':
          diagnosis = `Sua express√£o reflete tristeza, com frequ√™ncia card√≠aca de ${heartRate} bpm e tom de voz baixo, indicando introspec√ß√£o ou sobrecarga emocional.`;
          triggers = 'Isso pode estar ligado a saudades, estresse acumulado ou uma perda recente.';
          suggestion = 'Experimente medita√ß√£o guiada por 5 minutos ou escreva seus pensamentos.';
          personalizedPlan = 'Plano: 5 minutos de respira√ß√£o consciente e consulta com apoio emocional.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/apoio-emocional.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Explorar Apoio Emocional</button></div>';
          break;
        case 'anger':
          diagnosis = `Sua express√£o mostra raiva, com frequ√™ncia card√≠aca de ${heartRate} bpm e tom de voz elevado, sugerindo tens√£o ou frustra√ß√£o.`;
          triggers = 'Pode ser devido a um conflito recente, press√£o no trabalho ou uma situa√ß√£o irritante.';
          suggestion = 'Tente uma caminhada r√°pida para liberar a tens√£o ou pratique exerc√≠cios de respira√ß√£o profunda.';
          personalizedPlan = 'Plano: 10 minutos de alongamento e pr√°tica de mindfulness para aliviar a tens√£o.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/apoio-emocional.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Explorar Apoio Emocional</button></div>';
          break;
        case 'fear':
          diagnosis = `Sua express√£o indica medo, com frequ√™ncia card√≠aca de ${heartRate} bpm e tom de voz tr√™mulo, refletindo ansiedade ou incerteza.`;
          triggers = 'Pode estar relacionado a uma situa√ß√£o de incerteza, preocupa√ß√£o com o futuro ou um evento estressante.';
          suggestion = 'Pratique a t√©cnica de respira√ß√£o 4-7-8 para acalmar o sistema nervoso.';
          personalizedPlan = 'Plano: 5 minutos de respira√ß√£o 4-7-8 e uma sess√£o de relaxamento guiado.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/apoio-emocional.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Explorar Apoio Emocional</button></div>';
          break;
        case 'surprise':
          diagnosis = `Voc√™ parece surpreso, com frequ√™ncia card√≠aca de ${heartRate} bpm e tom de voz agudo, indicando um momento inesperado.`;
          triggers = 'Pode ser resultado de uma novidade, uma not√≠cia inesperada ou uma mudan√ßa repentina.';
          suggestion = 'Aproveite a energia da surpresa para explorar algo novo ou refletir sobre o que causou essa rea√ß√£o.';
          personalizedPlan = 'Plano: 10 minutos de escrita reflexiva sobre o evento que causou surpresa.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/planos.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Assinar Plano Premium</button></div>';
          break;
        case 'disgust':
          diagnosis = `Sua express√£o reflete nojo, com frequ√™ncia card√≠aca de ${heartRate} bpm e tom de voz de repulsa, indicando desagrado.`;
          triggers = 'Pode estar ligado a uma situa√ß√£o desconfort√°vel, algo que voc√™ considera inaceit√°vel ou um ambiente desagrad√°vel.';
          suggestion = 'Tente se afastar da fonte do desagrado e pratique uma atividade que traga conforto.';
          personalizedPlan = 'Plano: 10 minutos de relaxamento com m√∫sica calma e um ch√° quente.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/apoio-emocional.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Explorar Apoio Emocional</button></div>';
          break;
        case 'neutral':
          diagnosis = `Sua express√£o √© neutra, com frequ√™ncia card√≠aca de ${heartRate} bpm e tom de voz est√°vel, sugerindo calma ou concentra√ß√£o.`;
          triggers = 'Pode indicar que voc√™ est√° em um estado de equil√≠brio ou focado em uma tarefa.';
          suggestion = 'Continue mantendo esse equil√≠brio com pr√°ticas de mindfulness ou pausas regulares.';
          personalizedPlan = 'Plano: 5 minutos de alongamento leve e hidrata√ß√£o regular.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/planos.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Assinar Plano Premium</button></div>';
          break;
        default:
          diagnosis = `Emo√ß√£o predominante: ${primaryEmotionInPortuguese}, com frequ√™ncia card√≠aca de ${heartRate} bpm.`;
          triggers = 'Estamos analisando poss√≠veis gatilhos para essa emo√ß√£o.';
          suggestion = 'Tente refletir sobre o que pode estar influenciando esse estado.';
          personalizedPlan = 'Plano: 5 minutos de pausa para reflex√£o.';
          ctaButtons = '<div class="mt-6"><button onclick="window.location.href=\'/planos.html\'" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Assinar Plano Premium</button></div>';
      }

      if (isSimulated) {
        diagnosis += ' <span class="text-yellow-300"> (Frequ√™ncia card√≠aca estimada devido a falha na medi√ß√£o precisa)</span>';
      }

      return { diagnosis, triggers, suggestion, personalizedPlan, ctaButtons, ageRangeMin, ageRangeMax, primaryEmotionInPortuguese };
    }
  </script>

  <script>
    document.addEventListener('DOMContentLoaded', () => {
      console.log('DOM carregado, inicializando scanner...');
      const video = document.getElementById('video');
      const placeholder = document.getElementById('video-placeholder');
      const result = document.getElementById('scanner-result');
      const vrContainer = document.getElementById('vr-container');
      
      if (result) {
        result.style.display = 'none';
        result.innerHTML = '';
        console.log('Resultado inicializado como oculto');
      }

      if (video && placeholder) {
        video.classList.add('hidden');
        placeholder.classList.remove('hidden');
        console.log('Camera and microphone will be initialized on user action');
      } else {
        console.error('Elementos de v√≠deo ou placeholder n√£o encontrados');
      }

      initScrollAnimations();

      const hamburger = document.getElementById('hamburger-menu');
      const mobileMenu = document.getElementById('mobile-menu');
      if (hamburger && mobileMenu) {
        hamburger.addEventListener('click', () => {
          mobileMenu.classList.toggle('hidden');
        });
      }

      const servicesToggle = document.getElementById('services-toggle');
      const servicesMenu = document.getElementById('services-menu');
      if (servicesToggle && servicesMenu) {
        servicesToggle.addEventListener('click', () => {
          servicesMenu.classList.toggle('hidden');
        });
      }

      function initScrollAnimations() {
        const elements = document.querySelectorAll('.animate-on-scroll');
        const observer = new IntersectionObserver((entries, observer) => {
          entries.forEach(entry => {
            if (entry.isIntersecting) {
              entry.target.classList.add('active');
              observer.unobserve(entry.target);
            }
          });
        }, { threshold: 0.1 });
        elements.forEach(element => observer.observe(element));
      }
    });

    function changeLanguage() {
      const lang = document.getElementById('language-selector').value;
      console.log(`Mudando idioma para: ${lang}`);
      // Implementar l√≥gica de troca de idioma aqui
    }
  </script>

  <script>
    let lastDetectedEmotion = null; // Vari√°vel global para armazenar a emo√ß√£o predominante

    function speak(text) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'pt-BR';
      window.speechSynthesis.speak(utterance);
    }

    // Fun√ß√µes Auxiliares
    function fft(signal) {
      const n = signal.length;
      if (n <= 1) return signal;

      const even = [];
      const odd = [];
      for (let i = 0; i < n; i++) {
        if (i % 2 === 0) even.push(signal[i]);
        else odd.push(signal[i]);
      }

      const evenFFT = fft(even);
      const oddFFT = fft(odd);
      const result = new Array(n).fill(0);

      for (let i = 0; i < n / 2; i++) {
        const theta = -2 * Math.PI * i / n;
        const t = {
          re: Math.cos(theta) * oddFFT[i],
          im: Math.sin(theta) * oddFFT[i]
        };
        result[i] = evenFFT[i] + t.re;
        result[i + n / 2] = evenFFT[i] - t.re;
      }
      return result;
    }

    function getDominantFrequency(signal, sampleRate) {
      const n = signal.length;
      const fftResult = fft(signal);
      const magnitudes = fftResult.slice(0, n / 2).map((val, i) => {
        return Math.sqrt(val * val);
      });

      let maxMag = 0;
      let maxIndex = 0;
      for (let i = 1; i < magnitudes.length; i++) {
        if (magnitudes[i] > maxMag) {
          maxMag = magnitudes[i];
          maxIndex = i;
        }
      }

      const freq = maxIndex * sampleRate / n;
      return freq;
    }

    // Fun√ß√£o Principal
    async function captureAndAnalyze() {
      console.log('Iniciando an√°lise facial e biom√©trica...');
      const canvas = document.getElementById('canvas');
      const video = document.getElementById('video');
      const placeholder = document.getElementById('video-placeholder');
      const result = document.getElementById('scanner-result');
      const ppgOverlay = document.getElementById('ppg-overlay');
      const ppgProgressBar = document.getElementById('ppg-progress-bar');
      const micPrompt = document.getElementById('mic-prompt');
      const speechOutput = document.getElementById('speech-output');
      let audioContext = null;
      let analyser = null;
      let videoStream = null;
      let audioStream = null;

      if (!canvas || !video || !result || !placeholder || !ppgOverlay || !ppgProgressBar || !micPrompt || !speechOutput) {
        console.error('Elementos necess√°rios n√£o encontrados:', { canvas, video, result, placeholder, ppgOverlay, ppgProgressBar, micPrompt, speechOutput });
        return;
      }

      // Step 1: Request video stream (camera only)
      try {
        videoStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        video.srcObject = videoStream;
        video.classList.remove('hidden');
        placeholder.classList.add('hidden');
        console.log('C√¢mera inicializada com sucesso');
      } catch (error) {
        console.error('Erro ao acessar a c√¢mera:', error);
        video.classList.add('hidden');
        placeholder.classList.remove('hidden');
        result.style.display = 'block';
        let errorMessage = '<p class="fade-in">üö´ Erro: n√£o foi poss√≠vel acessar a c√¢mera. Permita o acesso e tente novamente.</p>';
        if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
          const videoTracks = videoStream ? videoStream.getVideoTracks().length : 0;
          if (videoTracks === 0) {
            errorMessage = '<p class="fade-in">üö´ Por favor, permita o acesso √† c√¢mera para continuar.</p>';
          }
        }
        result.innerHTML = `${errorMessage}<div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>`;
        return;
      }

      window.speechSynthesis.cancel();
      result.style.display = 'block';
      result.innerHTML = '<p class="fade-in">‚è≥ Preparando an√°lise<span class="loading-dots"></span></p>';

      // Step 2: Speech recognition with real-time feedback
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      let recognition = SpeechRecognition ? new SpeechRecognition() : null;
      let spokenText = '';

      if (recognition) {
        try {
          // Request audio stream for speech recognition
          audioStream = await navigator.mediaDevices.getUserMedia({ video: false, audio: true });
          console.log('Microfone inicializado para reconhecimento de voz');

          recognition.lang = 'pt-BR';
          recognition.continuous = false; // Stop after first result, but we'll manage manually
          recognition.interimResults = true; // Show real-time text
          micPrompt.style.display = 'flex';
          result.innerHTML = '<p class="fade-in">üéôÔ∏è Leia a frase "Estou me sentindo bem hoje" para iniciar a an√°lise.</p>';
          speak('Leia a frase "Estou me sentindo bem hoje" para iniciar a an√°lise.');

          recognition.onresult = (event) => {
            let interimTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; i++) {
              const transcript = event.results[i][0].transcript;
              if (event.results[i].isFinal) {
                spokenText += transcript;
              } else {
                interimTranscript += transcript;
              }
            }
            speechOutput.textContent = (interimTranscript || spokenText).trim();
            console.log('Texto falado:', speechOutput.textContent);

            // Check if the phrase is complete
            const spokenLower = spokenText.toLowerCase().trim();
            if (spokenLower.includes('estou me sentindo bem hoje')) {
              recognition.stop();
              micPrompt.style.display = 'none';
            }
          };

          recognition.onerror = (event) => {
            console.error('Erro no reconhecimento de voz:', event.error);
            throw event.error;
          };

          recognition.onend = () => {
            if (audioStream) {
              audioStream.getAudioTracks().forEach(track => track.stop());
              audioStream = null;
              console.log('Microfone desativado ap√≥s captura de voz');
            }
            if (!spokenText.toLowerCase().includes('estou me sentindo bem hoje')) {
              result.innerHTML = '<p class="fade-in">ü§î Frase n√£o reconhecida. Diga "Estou me sentindo bem hoje" e tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
              speak('Frase n√£o reconhecida. Diga "Estou me sentindo bem hoje" e tente novamente.');
              speechOutput.textContent = ''; // Clear speech output on error
              if (videoStream) {
                videoStream.getVideoTracks().forEach(track => track.stop());
                video.classList.add('hidden');
                placeholder.classList.remove('hidden');
              }
              return;
            }
            // Proceed to next steps (lighting, face detection, etc.)
            proceedWithAnalysis();
          };

          recognition.start();

          // Set a timeout to handle no speech after 15 seconds
          setTimeout(() => {
            if (recognition && spokenText.toLowerCase().includes('estou me sentindo bem hoje')) {
              recognition.stop();
            }
          }, 15000);

        } catch (error) {
          console.error('Erro no reconhecimento de voz:', error);
          micPrompt.style.display = 'none';
          if (audioStream) {
            audioStream.getAudioTracks().forEach(track => track.stop());
            audioStream = null;
            console.log('Microfone desativado devido a erro no reconhecimento de voz');
          }
          let errorMessage = 'üö´ N√£o conseguimos ouvir sua voz. Verifique o microfone e tente novamente.';
          if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
            errorMessage = 'üö´ Permiss√£o para o microfone negada. Por favor, permita o acesso e tente novamente.';
          } else if (error === 'Timeout: No speech detected within 10 seconds') {
            errorMessage = 'üö´ Nenhuma fala detectada em 15 segundos. Fale mais alto ou verifique o microfone.';
          } else if (error.name === 'NotFoundError') {
            errorMessage = 'üö´ Nenhum microfone detectado. Conecte um microfone e tente novamente.';
          }
          result.innerHTML = `<p class="fade-in">${errorMessage}</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>`;
          speak(errorMessage.replace('üö´ ', ''));
          speechOutput.textContent = ''; // Clear speech output on error
          if (videoStream) {
            videoStream.getVideoTracks().forEach(track => track.stop());
            video.classList.add('hidden');
            placeholder.classList.remove('hidden');
          }
          return;
        }
      } else {
        result.innerHTML = '<p class="fade-in">üö´ Reconhecimento de voz n√£o dispon√≠vel neste navegador. Ative manualmente para continuar.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
        speak('Reconhecimento de voz n√£o dispon√≠vel. Ative manualmente para continuar.');
        speechOutput.textContent = ''; // Clear speech output on error
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
        }
        return;
      }

      async function proceedWithAnalysis() {
        // Step 3: Check lighting conditions
        const context = canvas.getContext('2d');
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
        let brightnessSum = 0;
        for (let i = 0; i < imageData.data.length; i += 4) {
          const r = imageData.data[i];
          const g = imageData.data[i + 1];
          const b = imageData.data[i + 2];
          brightnessSum += (0.299 * r + 0.587 * g + 0.114 * b);
        }
        const averageBrightness = brightnessSum / (imageData.data.length / 4);
        if (averageBrightness < 50) {
          result.innerHTML = '<p class="fade-in">üåô A ilumina√ß√£o est√° muito baixa. Ajuste a luz para continuar.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
          speak('A ilumina√ß√£o est√° muito baixa. Ajuste a luz e tente novamente.');
          speechOutput.textContent = ''; // Clear speech output
          if (videoStream) {
            videoStream.getVideoTracks().forEach(track => track.stop());
            video.classList.add('hidden');
            placeholder.classList.remove('hidden');
          }
          return;
        }

        // Step 4: Face detection (optimized)
        let faceRect = null;
        const tracker = new tracking.ObjectTracker('face');
        tracker.setInitialScale(4);
        tracker.setStepSize(2);
        tracker.setEdgesDensity(0.1);
        tracking.track('#video', tracker);
        tracker.on('track', event => {
          if (event.data.length > 0) {
            faceRect = event.data[0];
          }
        });

        let faceDetected = false;
        for (let i = 0; i < 30; i++) {
          if (faceRect) {
            faceDetected = true;
            break;
          }
          await new Promise(resolve => setTimeout(resolve, 100));
        }

        if (!faceDetected) {
          result.innerHTML = '<p class="fade-in">ü§î N√£o conseguimos detectar seu rosto. Centralize-se na c√¢mera e tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
          speak('N√£o conseguimos detectar seu rosto. Centralize-se na c√¢mera e tente novamente.');
          tracker.stop();
          speechOutput.textContent = ''; // Clear speech output
          if (videoStream) {
            videoStream.getVideoTracks().forEach(track => track.stop());
            video.classList.add('hidden');
            placeholder.classList.remove('hidden');
          }
          return;
        }

        // Step 5: PPG (heart rate) measurement
        const PPG_DURATION = 15;
        const FRAME_RATE = 30;
        const TOTAL_FRAMES = PPG_DURATION * FRAME_RATE;
        const greenValues = [];
        let startTime = Date.now();
        result.innerHTML = '<p class="fade-in">‚ù§Ô∏è Fique parado por 15 segundos para medir sua frequ√™ncia card√≠aca.</p>';
        ppgOverlay.classList.add('active');

        while ((Date.now() - startTime) / 1000 < PPG_DURATION) {
          const elapsed = (Date.now() - startTime) / 1000;
          const progress = (elapsed / PPG_DURATION) * 100;
          ppgProgressBar.style.width = `${progress}%`;

          if (!faceRect) {
            result.innerHTML = '<p class="fade-in">üõë Movimenta√ß√£o detectada. Fique parado e tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
            speak('Movimenta√ß√£o detectada. Fique parado e tente novamente.');
            ppgOverlay.classList.remove('active');
            tracker.stop();
            speechOutput.textContent = ''; // Clear speech output
            if (videoStream) {
              videoStream.getVideoTracks().forEach(track => track.stop());
              video.classList.add('hidden');
              placeholder.classList.remove('hidden');
            }
            return;
          }

          context.drawImage(video, 0, 0, canvas.width, canvas.height);
          const foreheadX = faceRect.x + faceRect.width
                        ppgOverlay.classList.remove('active');
        tracker.stop();

        let heartRate = 0;
        let isSimulated = false;
        try {
          const mean = greenValues.reduce((a, b) => a + b, 0) / greenValues.length;
          const detrended = greenValues.map(val => val - mean);
          const maxVal = Math.max(...detrended.map(Math.abs));
          const normalized = detrended.map(val => val / maxVal);
          const freq = getDominantFrequency(normalized, FRAME_RATE);
          heartRate = Math.round(freq * 60);
          if (heartRate < 40 || heartRate > 180) {
            throw new Error('Heart rate out of realistic range');
          }
        } catch (error) {
          console.error('PPG analysis failed:', error);
          heartRate = Math.floor(60 + (Math.random() * 40));
          isSimulated = true;
        }

        // Step 6: Facial analysis
        result.innerHTML = '<p class="fade-in">‚è≥ Analisando express√£o facial<span class="loading-dots"></span></p>';
        const captures = [];
        const audioCaptures = [];
        try {
          for (let i = 0; i < 2; i++) {
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            const imageBase64 = canvas.toDataURL('image/jpeg').split(',')[1];
            captures.push(imageBase64);

            const simulatedVoiceTone = 100 + Math.random() * 50; // Arbitrary range
            audioCaptures.push(simulatedVoiceTone);
            await new Promise(resolve => setTimeout(resolve, 100));
          }
        } catch (error) {
          console.error('Erro durante a an√°lise:', error);
          result.innerHTML = '<p class="fade-in">üö´ Erro durante a an√°lise. Tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
          speechOutput.textContent = ''; // Clear speech output
          if (videoStream) {
            videoStream.getVideoTracks().forEach(track => track.stop());
            video.classList.add('hidden');
            placeholder.classList.remove('hidden');
          }
          return;
        } finally {
          if (videoStream) {
            videoStream.getVideoTracks().forEach(track => track.stop());
            video.classList.add('hidden');
            placeholder.classList.remove('hidden');
            console.log('C√¢mera fechada ap√≥s an√°lise');
          }
          videoStream = null;
        }

        // Step 7: Process results with Face++ API
        let bestResult = null;
        let maxConfidence = 0;

        for (let i = 0; i < captures.length; i++) {
          const formData = new FormData();
          formData.append('api_key', apiKey);
          formData.append('api_secret', apiSecret);
          formData.append('image_base64', captures[i]);
          formData.append('return_attributes', 'emotion,age');

          try {
            const response = await fetch('https://api-us.faceplusplus.com/facepp/v3/detect', {
              method: 'POST',
              body: formData
            });
            const data = await response.json();
            console.log('Resposta da API Face++:', data);

            if (data.faces && data.faces.length > 0) {
              const face = data.faces[0];
              const emotion = face.attributes.emotion;
              const emotionsSorted = Object.entries(emotion).sort((a, b) => b[1] - a[1]);
              const confidence = emotionsSorted[0][1];
              if (confidence > maxConfidence) {
                maxConfidence = confidence;
                bestResult = { emotion, age: face.attributes.age.value, heartRate, voiceTone: audioCaptures[i], isSimulated };
              }
            }
          } catch (error) {
            console.error('Erro ao analisar captura:', error);
          }
        }

        // Step 8: Display diagnosis
        if (bestResult && maxConfidence >= 50) {
          const { emotion, age, heartRate, voiceTone, isSimulated } = bestResult;
          const emotionsSorted = Object.entries(emotion).sort((a, b) => b[1] - a[1]);
          const primaryEmotion = emotionsSorted[0][0];
          lastDetectedEmotion = primaryEmotion; // Armazena a emo√ß√£o predominante

          // Generate diagnosis using the new function
          const diag = generateDiagnosis(primaryEmotion, heartRate, age, isSimulated);

          // Build and display the diagnosis HTML
          const diagnosisHTML = `
            <h3 class="text-2xl font-bold mb-4 fade-in">Resultado do Diagn√≥stico</h3>
            <p class="fade-in"><strong>Emo√ß√£o Predominante:</strong> ${diag.primaryEmotionInPortuguese.charAt(0).toUpperCase() + diag.primaryEmotionInPortuguese.slice(1)}</p>
            <p class="fade-in"><strong>Idade Aparente:</strong> Entre ${diag.ageRangeMin} e ${diag.ageRangeMax} anos</p>
            <p class="fade-in mt-2">${diag.diagnosis}</p>
            <p class="fade-in mt-2"><strong>Poss√≠veis Gatilhos:</strong> ${diag.triggers}</p>
            <p class="fade-in mt-2"><strong>Sugest√£o:</strong> ${diag.suggestion}</p>
            <p class="fade-in mt-2"><strong>Plano Personalizado:</strong> ${diag.personalizedPlan}</p>
            ${diag.ctaButtons}
          `;

          result.innerHTML = diagnosisHTML;
          speechOutput.textContent = ''; // Clear the speech output after diagnosis
          speak(`Seu diagn√≥stico est√° pronto. Emo√ß√£o predominante: ${diag.primaryEmotionInPortuguese.charAt(0).toUpperCase() + diag.primaryEmotionInPortuguese.slice(1)}. ${diag.diagnosis}`);
        } else {
          result.innerHTML = '<p class="fade-in">üö´ N√£o foi poss√≠vel determinar uma emo√ß√£o com confian√ßa suficiente. Tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
          speechOutput.textContent = ''; // Clear the speech output
          speak('N√£o foi poss√≠vel determinar uma emo√ß√£o com confian√ßa suficiente. Tente novamente.');
        }
      }
    }

    // Fun√ß√µes de Eventos
    async function initMedicalConsult() {
      const result = document.getElementById('scanner-result');
      if (result) {
        result.style.display = 'block';
        result.innerHTML = '<p class="fade-in">üìû Conectando a um consultor m√©dico<span class="loading-dots"></span></p>';
        speak('Conectando a um consultor m√©dico.');
        setTimeout(() => {
          window.location.href = '/medical-ai.html';
        }, 3000);
      }
    }

    function toggleVR() {
      const vrContainer = document.getElementById('vr-container');
      if (vrContainer) {
        let vrContent = '';
        let vrMessage = 'Bem-vindo ao Relaxamento VR/AR!';
        let vrIframeSrc = 'https://example.com/vr-nature-walk'; // URL padr√£o

        // Personaliza o VR/AR com base na emo√ß√£o detectada
        switch (lastDetectedEmotion) {
          case 'sadness':
            vrMessage = 'Relaxe em uma praia calma para aliviar a tristeza.';
            vrIframeSrc = 'https://example.com/vr-beach'; // Substitua por uma URL real
            break;
          case 'anger':
            vrMessage = 'Explore uma floresta serena para acalmar a raiva.';
            vrIframeSrc = 'https://example.com/vr-forest'; // Substitua por uma URL real
            break;
          case 'happiness':
            vrMessage = 'Aproveite um parque vibrante para manter sua alegria!';
            vrIframeSrc = 'https://example.com/vr-park'; // Substitua por uma URL real
            break;
          case 'fear':
            vrMessage = 'Mergulhe em um ambiente seguro para reduzir o medo.';
            vrIframeSrc = 'https://example.com/vr-safe-space'; // Substitua por uma URL real
            break;
          case 'surprise':
            vrMessage = 'Descubra um cen√°rio novo e inspirador!';
            vrIframeSrc = 'https://example.com/vr-new-landscape'; // Substitua por uma URL real
            break;
          case 'disgust':
            vrMessage = 'Renove-se em um ambiente puro e tranquilo.';
            vrIframeSrc = 'https://example.com/vr-pure-landscape'; // Substitua por uma URL real
            break;
          case 'neutral':
            vrMessage = 'Mantenha o equil√≠brio com uma caminhada virtual na natureza.';
            vrIframeSrc = 'https://example.com/vr-nature-walk'; // URL padr√£o
            break;
          default:
            vrMessage = 'Explore uma caminhada virtual na natureza.';
            vrIframeSrc = 'https://example.com/vr-nature-walk'; // URL padr√£o
        }

        vrContent = `
          <p class="text-lg text-gray-300 fade-in">${vrMessage}</p>
          <iframe src="${vrIframeSrc}" width="400" height="300" frameborder="0" allowfullscreen></iframe>
        `;

        vrContainer.innerHTML = vrContent;
        vrContainer.style.display = vrContainer.style.display === 'block' ? 'none' : 'block';
        speak(vrContainer.style.display === 'block' ? vrMessage : 'Relaxamento VR/AR desativado.');
      }
    }
  </script>
</body>
</html>
      }

      // Step 6: Facial analysis
      result.innerHTML = '<p class="fade-in">‚è≥ Analisando express√£o facial<span class="loading-dots"></span></p>';
      const captures = [];
      const audioCaptures = [];
      try {
        for (let i = 0; i < 2; i++) {
          context.drawImage(video, 0, 0, canvas.width, canvas.height);
          const imageBase64 = canvas.toDataURL('image/jpeg').split(',')[1];
          captures.push(imageBase64);

          const simulatedVoiceTone = 100 + Math.random() * 50; // Arbitrary range
          audioCaptures.push(simulatedVoiceTone);
          await new Promise(resolve => setTimeout(resolve, 100));
        }
      } catch (error) {
        console.error('Erro durante a an√°lise:', error);
        result.innerHTML = '<p class="fade-in">üö´ Erro durante a an√°lise. Tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
        speechOutput.textContent = ''; // Clear speech output
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
        }
        return;
      } finally {
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
          console.log('C√¢mera fechada ap√≥s an√°lise');
        }
        videoStream = null;
      }

      // Step 7: Process results with Face++ API
      let bestResult = null;
      let maxConfidence = 0;

      for (let i = 0; i < captures.length; i++) {
        const formData = new FormData();
        formData.append('api_key', apiKey);
        formData.append('api_secret', apiSecret);
        formData.append('image_base64', captures[i]);
        formData.append('return_attributes', 'emotion,age');

        try {
          const response = await fetch('https://api-us.faceplusplus.com/facepp/v3/detect', {
            method: 'POST',
            body: formData
          });
          const data = await response.json();
          console.log('Resposta da API Face++:', data);

          if (data.faces && data.faces.length > 0) {
            const face = data.faces[0];
            const emotion = face.attributes.emotion;
            const emotionsSorted = Object.entries(emotion).sort((a, b) => b[1] - a[1]);
            const confidence = emotionsSorted[0][1];
            if (confidence > maxConfidence) {
              maxConfidence = confidence;
              bestResult = { emotion, age: face.attributes.age.value, heartRate, voiceTone: audioCaptures[i], isSimulated };
            }
          }
        } catch (error) {
          console.error('Erro ao analisar captura:', error);
        }
      }

      // Step 8: Display diagnosis
      if (bestResult && maxConfidence >= 50) {
        const { emotion, age, heartRate, voiceTone, isSimulated } = bestResult;
        const emotionsSorted = Object.entries(emotion).sort((a, b) => b[1] - a[1]);
        const primaryEmotion = emotionsSorted[0][0];
        lastDetectedEmotion = primaryEmotion; // Armazena a emo√ß√£o predominante

        // Generate diagnosis using the new function
        const diag = generateDiagnosis(primaryEmotion, heartRate, age, isSimulated);

        // Build and display the diagnosis HTML
        const diagnosisHTML = `
          <h3 class="text-2xl font-bold mb-4 fade-in">Resultado do Diagn√≥stico</h3>
          <p class="fade-in"><strong>Emo√ß√£o Predominante:</strong> ${diag.primaryEmotionInPortuguese.charAt(0).toUpperCase() + diag.primaryEmotionInPortuguese.slice(1)}</p>
                  <p class="fade-in"><strong>Idade Aparente:</strong> Entre ${diag.ageRangeMin} e ${diag.ageRangeMax} anos</p>
          <p class="fade-in mt-2">${diag.diagnosis}</p>
          <p class="fade-in mt-2"><strong>Poss√≠veis Gatilhos:</strong> ${diag.triggers}</p>
          <p class="fade-in mt-2"><strong>Sugest√£o:</strong> ${diag.suggestion}</p>
          <p class="fade-in mt-2"><strong>Plano Personalizado:</strong> ${diag.personalizedPlan}</p>
          ${diag.ctaButtons}
        `;

        result.innerHTML = diagnosisHTML;
        speechOutput.textContent = ''; // Clear the speech output after diagnosis
        speak(`Seu diagn√≥stico est√° pronto. Emo√ß√£o predominante: ${diag.primaryEmotionInPortuguese.charAt(0).toUpperCase() + diag.primaryEmotionInPortuguese.slice(1)}. ${diag.diagnosis}`);
      } else {
        result.innerHTML = '<p class="fade-in">üö´ N√£o foi poss√≠vel determinar uma emo√ß√£o com confian√ßa suficiente. Tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
        speechOutput.textContent = ''; // Clear the speech output
        speak('N√£o foi poss√≠vel determinar uma emo√ß√£o com confian√ßa suficiente. Tente novamente.');
      }
    }
  }

  // Fun√ß√µes de Eventos
  async function initMedicalConsult() {
    const result = document.getElementById('scanner-result');
    if (result) {
      result.style.display = 'block';
      result.innerHTML = '<p class="fade-in">üìû Conectando a um consultor m√©dico<span class="loading-dots"></span></p>';
      speak('Conectando a um consultor m√©dico.');
      setTimeout(() => {
        window.location.href = '/medical-ai.html';
      }, 3000);
    }
  }

  function toggleVR() {
    const vrContainer = document.getElementById('vr-container');
    if (vrContainer) {
      let vrContent = '';
      let vrMessage = 'Bem-vindo ao Relaxamento VR/AR!';
      let vrIframeSrc = 'https://example.com/vr-nature-walk'; // URL padr√£o

      // Personaliza o VR/AR com base na emo√ß√£o detectada
      switch (lastDetectedEmotion) {
        case 'sadness':
          vrMessage = 'Relaxe em uma praia calma para aliviar a tristeza.';
          vrIframeSrc = 'https://example.com/vr-beach'; // Substitua por uma URL real
          break;
        case 'anger':
          vrMessage = 'Explore uma floresta serena para acalmar a raiva.';
          vrIframeSrc = 'https://example.com/vr-forest'; // Substitua por uma URL real
          break;
        case 'happiness':
          vrMessage = 'Aproveite um parque vibrante para manter sua alegria!';
          vrIframeSrc = 'https://example.com/vr-park'; // Substitua por uma URL real
          break;
        case 'fear':
          vrMessage = 'Mergulhe em um ambiente seguro para reduzir o medo.';
          vrIframeSrc = 'https://example.com/vr-safe-space'; // Substitua por uma URL real
          break;
        case 'surprise':
          vrMessage = 'Descubra um cen√°rio novo e inspirador!';
          vrIframeSrc = 'https://example.com/vr-new-landscape'; // Substitua por uma URL real
          break;
        case 'disgust':
          vrMessage = 'Renove-se em um ambiente puro e tranquilo.';
          vrIframeSrc = 'https://example.com/vr-pure-landscape'; // Substitua por uma URL real
          break;
        case 'neutral':
          vrMessage = 'Mantenha o equil√≠brio com uma caminhada virtual na natureza.';
          vrIframeSrc = 'https://example.com/vr-nature-walk'; // URL padr√£o
          break;
        default:
          vrMessage = 'Explore uma caminhada virtual na natureza.';
          vrIframeSrc = 'https://example.com/vr-nature-walk'; // URL padr√£o
      }

      vrContent = `
        <p class="text-lg text-gray-300 fade-in">${vrMessage}</p>
        <iframe src="${vrIframeSrc}" width="400" height="300" frameborder="0" allowfullscreen></iframe>
      `;

      vrContainer.innerHTML = vrContent;
      vrContainer.style.display = vrContainer.style.display === 'block' ? 'none' : 'block';
      speak(vrContainer.style.display === 'block' ? vrMessage : 'Relaxamento VR/AR desativado.');
    }
  }
</script>
</body>
</html>
