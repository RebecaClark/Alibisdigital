<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">    
  <meta name="description" content="Teste o Scanner Emocional da √Ålibis Digital para um diagn√≥stico emocional detalhado e descubra planos para bem-estar.">
  <meta name="keywords" content="scanner emocional, criar √°libi, apoio emocional, medical IA, bem-estar, estresse">
  <meta name="author" content="√Ålibis Digital">
  <title>Scanner Emocional - √Ålibis Digital</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tracking.js/1.1.3/tracking-min.js" defer></script>
  <style>
    html { scroll-behavior: smooth; }
    body { 
      position: relative; 
      overflow-x: hidden; 
      min-height: 100vh; 
      color: #e5e7eb; 
      text-shadow: 0 0.5px rgba(0, 0, 0, 0.5); 
      font-family: Arial, sans-serif;
    }
    #particles-js { 
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
      background: #0b1120;
    }
    #particles-fallback {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
      background: #0b1120;
      display: none;
      color: #e5e7eb;
      text-align: center;
      padding-top: 20%;
      font-size: 1.2rem;
    }
    .fade-in { animation: fadeIn 1s ease-in-out; }
    .slide-in-left { animation: slideInLeft 1.2s ease-in-out; }
    .slide-in-right { animation: slideInRight 1.2s ease-in-out; }
    @keyframes fadeIn { from { opacity: 0; transform: translateY(30px); } to { opacity: 1; transform: translateY(0); } }
    @keyframes slideInLeft { from { opacity: 0; transform: translateX(-60px); } to { opacity: 1; transform: translateX(0); } }
    @keyframes slideInRight { from { opacity: 0; transform: translateX(60px); } to { opacity: 1; transform: translateX(0); } }
    .shine { position: relative; overflow: hidden; }
    .shine::after { 
      content: ''; 
      position: absolute; 
      top: -60%; 
      left: -60%; 
      width: 220%; 
      height: 220%; 
      background: linear-gradient(45deg, rgba(255,255,255,0), rgba(255,255,255,0.2), rgba(255,255,255,0)); 
      transform: rotate(20deg); 
      animation: shine 4s infinite linear; 
    }
    @keyframes shine { 
      0% { transform: translateX(-120%) rotate(20deg); } 
      100% { transform: translateX(120%) rotate(20deg); } 
    }
    .futuristic-btn { 
      background: linear-gradient(45deg, #7C3AED, #22d3ee); 
      box-shadow: 0 0 15px #22d3ee; 
      transition: transform 0.3s ease, box-shadow 0.3s ease; 
      animation: neonPulse 1.5s infinite alternate; 
    }
    .futuristic-btn:hover { 
      transform: translateY(-5px); 
      box-shadow: 0 0 25px #22d3ee, 0 0 35px #22d3ee; 
    }
    @keyframes neonPulse { 
      0% { box-shadow: 0 0 5px #22d3ee, 0 0 10px #22d3ee; } 
      100% { box-shadow: 0 0 15px #22d3ee, 0 0 25px #22d3ee; } 
    }
    .holo-nav {
      background: rgba(17, 24, 39, 0.8);
      backdrop-filter: blur(10px);
      border-bottom: 1px solid rgba(255, 255, 255, 0.1);
      animation: holoGlow 2s infinite alternate;
    }
    @keyframes holoGlow {
      0% { box-shadow: 0 0 10px #22d3ee, 0 0 20px #22d3ee; }
      100% { box-shadow: 0 0 20px #22d3ee, 0 0 30px #22d3ee; }
    }
    .holo-nav a, .holo-nav button { transition: color 0.3s ease; }
    .holo-nav a:hover, .holo-nav button:hover { 
      color: #22d3ee; 
      text-shadow: 0 0 5px #22d3ee; 
    }
    .dropdown-menu {
      background: rgba(31, 41, 55, 0.9);
      border: 1px solid #22d3ee;
      box-shadow: 0 0 10px #22d3ee;
      border-radius: 8px;
      padding: 8px 0;
      position: absolute;
      top: 100%;
      left: 0;
      display: none;
      width: 200px;
    }
    .dropdown-menu a {
      display: block;
      padding: 8px 16px;
      color: #e5e7eb;
      transition: all 0.3s ease;
    }
    .dropdown-menu a:hover {
      background: rgba(55, 65, 81, 0.8);
      color: #22d3ee;
    }
    .dropdown:hover .dropdown-menu { display: block; }
    .dropdown-menu-mobile {
      background: rgba(31, 41, 55, 0.9);
      border: 1px solid #22d3ee;
      box-shadow: 0 0 10px #22d3ee;
      border-radius: 8px;
      padding: 8px 0;
      width: 100%;
      position: static;
    }
    .dropdown-menu-mobile a {
      display: block;
      padding: 8px 16px;
      color: #e5e7eb;
      transition: all 0.3s ease;
    }
    .dropdown-menu-mobile a:hover {
      background: rgba(55, 65, 81, 0.8);
      color: #22d3ee;
    }
    .animate-on-scroll {
      opacity: 0;
      transform: translateY(50px);
      transition: opacity 0.9s ease-out, transform 0.9s ease-out;
    }
    .animate-on-scroll.visible {
      opacity: 1;
      transform: translateY(0);
    }
    .neon-box {
      background: linear-gradient(45deg, #1e1b4b, #22d3ee);
      border-radius: 15px;
      padding: 20px;
      box-shadow: 0 0 10px #22d3ee;
      animation: fadeIn 1s ease-in-out;
      max-width: 600px;
      margin: 0 auto;
      text-align: left;
    }
    .loading-dots::after {
      content: '';
      display: inline-block;
      width: 1em;
      height: 1em;
      animation: dots 1.5s steps(3, end) infinite;
    }
    @keyframes dots {
      0% { content: '.'; }
      33% { content: '..'; }
      66% { content: '...'; }
      100% { content: '.'; }
    }
    video {
      width: 400px;
      height: 300px;
      max-width: 100%;
      margin-left: auto;
      margin-right: auto;
      border-radius: 0.75rem;
      box-shadow: 0 0.25rem 0.5rem rgba(0, 0, 0, 0.2);
      border: 1px solid #22d3ee;
    }
    .video-placeholder {
      width: 400px;
      height: 300px;
      max-width: 100%;
      background: #1f2937;
      border-radius: 0.75rem;
      display: flex;
      align-items: center;
      justify-content: center;
      color: #e5e7eb;
      border: 1px solid #22d3ee;
    }
    .ppg-overlay {
      position: absolute;
      width: 400px;
      height: 300px;
      max-width: 100%;
      border-radius: 0.75rem;
      border: 2px dashed #22d3ee;
      pointer-events: none;
      display: none;
      flex-direction: column;
      justify-content: flex-end;
      align-items: center;
      padding-bottom: 10px;
    }
    .ppg-overlay.active {
      display: flex;
    }
    .ppg-progress-container {
      width: 80%;
      height: 20px;
      background: rgba(0, 0, 0, 0.5);
      border-radius: 10px;
      overflow: hidden;
      margin-top: 10px;
    }
    .ppg-progress-bar {
      height: 100%;
      background: linear-gradient(90deg, #22d3ee, #7C3AED);
      width: 0%;
      transition: width 0.1s linear;
      box-shadow: 0 0 10px #22d3ee;
    }
    .ppg-stay-still {
      color: #22d3ee;
      font-size: 1rem;
      text-shadow: 0 0 5px #22d3ee;
      animation: pulseText 1.5s infinite;
      margin-bottom: 10px;
    }
    @keyframes pulseText {
      0% { opacity: 1; }
      50% { opacity: 0.7; }
      100% { opacity: 1; }
    }
    .mic-icon {
      display: inline-block;
      width: 24px;
      height: 24px;
      background: url('https://via.placeholder.com/24?text=üéôÔ∏è') no-repeat center;
      animation: pulseMic 1.5s infinite;
      margin-right: 8px;
    }
    @keyframes pulseMic {
      0% { transform: scale(1); opacity: 1; }
      50% { transform: scale(1.2); opacity: 0.7; }
      100% { transform: scale(1); opacity: 1; }
    }
    .mic-prompt {
      display: flex;
      align-items: center;
      justify-content: center;
      margin-top: 10px;
      color: #22d3ee;
      font-size: 1.1rem;
      text-shadow: 0 0 5px #22d3ee;
    }
    .testimonial-card {
      background: rgba(31, 41, 55, 0.9);
      border: 1px solid #22d3ee;
      border-radius: 10px;
      padding: 20px;
      margin: 10px;
      box-shadow: 0 0 10px #22d3ee;
    }
    .testimonial-img {
      width: 60px;
      height: 60px;
      border-radius: 50%;
      border: 2px solid #22d3ee;
      margin-right: 15px;
    }
    #chat-container {
      position: fixed;
      bottom: 20px;
      right: 20px;
      z-index: 1000;
    }
    #chat-bubble {
      background: linear-gradient(45deg, #7C3AED, #22d3ee);
      border-radius: 50%;
      width: 60px;
      height: 60px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      box-shadow: 0 0 15px #22d3ee;
      animation: pulse 2s infinite;
    }
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.05); }
      100% { transform: scale(1); }
    }
    #chat-window {
      display: none;
      background: rgba(17, 24, 39, 0.95);
      backdrop-filter: blur(10px);
      border: 1px solid #22d3ee;
      border-radius: 15px;
      width: 300px;
      height: 400px;
      position: absolute;
      bottom: 80px;
      right: 0;
      box-shadow: 0 0 20px #22d3ee;
    }
    #chat-messages {
      height: 300px;
      overflow-y: auto;
      padding: 10px;
      color: #e5e7eb;
    }
    #chat-input {
      background: rgba(55, 65, 81, 0.8);
      border: 1px solid #22d3ee;
      border-radius: 20px;
      padding: 10px;
      width: 100%;
      color: white;
    }
    .listening-indicator {
      display: none;
      color: #22d3ee;
      font-size: 0.9rem;
      text-align: center;
      margin-top: 5px;
    }
    .listening-indicator.active { display: block; }
    @media (max-width: 768px) {
      h1 { font-size: 2rem; }
      h2 { font-size: 1.5rem; }
      p { font-size: 0.9rem; }
      .max-w-4xl { max-width: 100%; padding: 0 1rem; }
      .max-w-6xl { max-width: 100%; padding: 0 1rem; }
      .grid { grid-template-columns: 1fr; }
      .flex { flex-direction: column; }
      .futuristic-btn { width: 100%; margin-bottom: 0.5rem; padding: 0.5rem 1rem; font-size: 0.9rem; }
      video, .video-placeholder { width: 360px; height: 270px; max-width: 90vw; }
      .ppg-overlay { width: 360px; height: 270px; max-width: 90vw; }
      .scanner-container { padding: 1rem; max-height: 80vh; }
      section#scanner, section#emotion-intro { padding-top: 1.5rem; padding-bottom: 1.5rem; }
      #chat-window { width: 90%; right: 5%; height: 350px; }
      #chat-messages { height: 250px; }
      .testimonial-card { padding: 15px; margin: 5px; }
      .testimonial-img { width: 50px; height: 50px; }
    }
    @media (max-width: 480px) {
      h1 { font-size: 1.8rem; }
      h2 { font-size: 1.3rem; }
      p { font-size: 0.85rem; }
      video, .video-placeholder { width: 320px; height: 240px; }
      .ppg-overlay { width: 320px; height: 240px; }
      .futuristic-btn { font-size: 0.8rem; }
      .neon-box { padding: 15px; }
    }
  </style>
<script>
  async function captureAndAnalyze() {
    console.log('Iniciando an√°lise facial e biom√©trica...');
    const canvas = document.getElementById('canvas');
    const video = document.getElementById('video');
    const placeholder = document.getElementById('video-placeholder');
    const result = document.getElementById('scanner-result');
    const ppgOverlay = document.getElementById('ppg-overlay');
    const ppgProgressBar = document.getElementById('ppg-progress-bar');
    const micPrompt = document.getElementById('mic-prompt');
    const speechOutput = document.getElementById('speech-output');
    let audioContext = null;
    let analyser = null;
    let videoStream = null;
    let audioStream = null;

    if (!canvas || !video || !result || !placeholder || !ppgOverlay || !ppgProgressBar || !micPrompt || !speechOutput) {
      console.error('Elementos necess√°rios n√£o encontrados:', { canvas, video, result, placeholder, ppgOverlay, ppgProgressBar, micPrompt, speechOutput });
      return;
    }

    // Step 1: Request video stream (camera only)
    try {
      videoStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
      video.srcObject = videoStream;
      video.classList.remove('hidden');
      placeholder.classList.add('hidden');
      console.log('C√¢mera inicializada com sucesso');
    } catch (error) {
      console.error('Erro ao acessar a c√¢mera:', error);
      video.classList.add('hidden');
      placeholder.classList.remove('hidden');
      result.style.display = 'block';
      let errorMessage = '<p class="fade-in">üö´ Erro: n√£o foi poss√≠vel acessar a c√¢mera. Permita o acesso e tente novamente.</p>';
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        const videoTracks = videoStream ? videoStream.getVideoTracks().length : 0;
        if (videoTracks === 0) {
          errorMessage = '<p class="fade-in">üö´ Por favor, permita o acesso √† c√¢mera para continuar.</p>';
        }
      }
      result.innerHTML = `${errorMessage}<div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>`;
      return;
    }

    window.speechSynthesis.cancel();
    result.style.display = 'block';
    result.innerHTML = '<p class="fade-in">‚è≥ Preparando an√°lise<span class="loading-dots"></span></p>';

    // Step 2: Speech recognition with real-time feedback
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition = SpeechRecognition ? new SpeechRecognition() : null;
    let spokenText = '';

    if (recognition) {
      try {
        // Request audio stream for speech recognition
        audioStream = await navigator.mediaDevices.getUserMedia({ video: false, audio: true });
        console.log('Microfone inicializado para reconhecimento de voz');

        recognition.lang = 'pt-BR';
        recognition.continuous = false; // Stop after first result, but we'll manage manually
        recognition.interimResults = true; // Show real-time text
        micPrompt.style.display = 'flex';
        result.innerHTML = '<p class="fade-in">üéôÔ∏è Leia a frase "Estou me sentindo bem hoje" para iniciar a an√°lise.</p>';
        speak('Leia a frase "Estou me sentindo bem hoje" para iniciar a an√°lise.');

        recognition.onresult = (event) => {
          let interimTranscript = '';
          for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            if (event.results[i].isFinal) {
              spokenText += transcript;
            } else {
              interimTranscript += transcript;
            }
          }
          speechOutput.textContent = (interimTranscript || spokenText).trim();
          console.log('Texto falado:', speechOutput.textContent);

          // Check if the phrase is complete
          const spokenLower = spokenText.toLowerCase().trim();
          if (spokenLower.includes('estou me sentindo bem hoje')) {
            recognition.stop();
            micPrompt.style.display = 'none';
          }
        };

        recognition.onerror = (event) => {
          console.error('Erro no reconhecimento de voz:', event.error);
          throw event.error;
        };

        recognition.onend = () => {
          if (audioStream) {
            audioStream.getAudioTracks().forEach(track => track.stop());
            audioStream = null;
            console.log('Microfone desativado ap√≥s captura de voz');
          }
          if (!spokenText.toLowerCase().includes('estou me sentindo bem hoje')) {
            result.innerHTML = '<p class="fade-in">ü§î Frase n√£o reconhecida. Diga "Estou me sentindo bem hoje" e tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
            speak('Frase n√£o reconhecida. Diga "Estou me sentindo bem hoje" e tente novamente.');
            speechOutput.textContent = ''; // Clear speech output on error
            if (videoStream) {
              videoStream.getVideoTracks().forEach(track => track.stop());
              video.classList.add('hidden');
              placeholder.classList.remove('hidden');
            }
            return;
          }
          // Proceed to next steps (lighting, face detection, etc.)
          proceedWithAnalysis();
        };

        recognition.start();

        // Set a timeout to handle no speech after 15 seconds
        setTimeout(() => {
          if (recognition && recognition.state !== 'inactive') {
            recognition.stop();
          }
        }, 15000);

      } catch (error) {
        console.error('Erro no reconhecimento de voz:', error);
        micPrompt.style.display = 'none';
        if (audioStream) {
          audioStream.getAudioTracks().forEach(track => track.stop());
          audioStream = null;
          console.log('Microfone desativado devido a erro no reconhecimento de voz');
        }
        let errorMessage = 'üö´ N√£o conseguimos ouvir sua voz. Verifique o microfone e tente novamente.';
        if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
          errorMessage = 'üö´ Permiss√£o para o microfone negada. Por favor, permita o acesso e tente novamente.';
        } else if (error === 'Timeout: No speech detected within 10 seconds') {
          errorMessage = 'üö´ Nenhuma fala detectada em 15 segundos. Fale mais alto ou verifique o microfone.';
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'üö´ Nenhum microfone detectado. Conecte um microfone e tente novamente.';
        }
        result.innerHTML = `<p class="fade-in">${errorMessage}</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>`;
        speak(errorMessage.replace('üö´ ', ''));
        speechOutput.textContent = ''; // Clear speech output on error
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
        }
        return;
      }
    } else {
      result.innerHTML = '<p class="fade-in">üö´ Reconhecimento de voz n√£o dispon√≠vel neste navegador. Ative manualmente para continuar.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
      speak('Reconhecimento de voz n√£o dispon√≠vel. Ative manualmente para continuar.');
      speechOutput.textContent = ''; // Clear speech output on error
      if (videoStream) {
        videoStream.getVideoTracks().forEach(track => track.stop());
        video.classList.add('hidden');
        placeholder.classList.remove('hidden');
      }
      return;
    }

    async function proceedWithAnalysis() {
      // Step 3: Check lighting conditions
      const context = canvas.getContext('2d');
      context.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
      let brightnessSum = 0;
      for (let i = 0; i < imageData.data.length; i += 4) {
        const r = imageData.data[i];
        const g = imageData.data[i + 1];
        const b = imageData.data[i + 2];
        brightnessSum += (0.299 * r + 0.587 * g + 0.114 * b);
      }
      const averageBrightness = brightnessSum / (imageData.data.length / 4);
      if (averageBrightness < 50) {
        result.innerHTML = '<p class="fade-in">üåô A ilumina√ß√£o est√° muito baixa. Ajuste a luz para continuar.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
        speak('A ilumina√ß√£o est√° muito baixa. Ajuste a luz e tente novamente.');
        speechOutput.textContent = ''; // Clear speech output
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
        }
        return;
      }

      // Step 4: Face detection (optimized)
      let faceRect = null;
      const tracker = new tracking.ObjectTracker('face');
      tracker.setInitialScale(4);
      tracker.setStepSize(2);
      tracker.setEdgesDensity(0.1);
      tracking.track('#video', tracker);
      tracker.on('track', event => {
        if (event.data.length > 0) {
          faceRect = event.data[0];
        }
      });

      let faceDetected = false;
      for (let i = 0; i < 30; i++) {
        if (faceRect) {
          faceDetected = true;
          break;
        }
        await new Promise(resolve => setTimeout(resolve, 100));
      }

      if (!faceDetected) {
        result.innerHTML = '<p class="fade-in">ü§î N√£o conseguimos detectar seu rosto. Centralize-se na c√¢mera e tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
        speak('N√£o conseguimos detectar seu rosto. Centralize-se na c√¢mera e tente novamente.');
        tracker.stop();
        speechOutput.textContent = ''; // Clear speech output
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
        }
        return;
      }

      // Step 5: PPG (heart rate) measurement
      const PPG_DURATION = 15;
      const FRAME_RATE = 30;
      const TOTAL_FRAMES = PPG_DURATION * FRAME_RATE;
      const greenValues = [];
      let startTime = Date.now();
      result.innerHTML = '<p class="fade-in">‚ù§Ô∏è Fique parado por 15 segundos para medir sua frequ√™ncia card√≠aca.</p>';
      ppgOverlay.classList.add('active');

      while ((Date.now() - startTime) / 1000 < PPG_DURATION) {
        const elapsed = (Date.now() - startTime) / 1000;
        const progress = (elapsed / PPG_DURATION) * 100;
        ppgProgressBar.style.width = `${progress}%`;

        if (!faceRect) {
          result.innerHTML = '<p class="fade-in">üõë Movimenta√ß√£o detectada. Fique parado e tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
          speak('Movimenta√ß√£o detectada. Fique parado e tente novamente.');
          ppgOverlay.classList.remove('active');
          tracker.stop();
          speechOutput.textContent = ''; // Clear speech output
          if (videoStream) {
            videoStream.getVideoTracks().forEach(track => track.stop());
            video.classList.add('hidden');
            placeholder.classList.remove('hidden');
          }
          return;
        }

        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const foreheadX = faceRect.x + faceRect.width * 0.3;
        const foreheadY = faceRect.y + faceRect.height * 0.2;
        const foreheadWidth = faceRect.width * 0.4;
        const foreheadHeight = faceRect.height * 0.2;
        const foreheadData = context.getImageData(foreheadX, foreheadY, foreheadWidth, foreheadHeight);
        let greenSum = 0;
        let pixelCount = 0;
        for (let i = 0; i < foreheadData.data.length; i += 4) {
          greenSum += foreheadData.data[i + 1];
          pixelCount++;
        }
        const averageGreen = greenSum / pixelCount;
        greenValues.push(averageGreen);
        await new Promise(resolve => setTimeout(resolve, 1000 / FRAME_RATE));
      }

      ppgOverlay.classList.remove('active');
      tracker.stop();

      let heartRate = 0;
      let isSimulated = false;
      try {
        const mean = greenValues.reduce((a, b) => a + b, 0) / greenValues.length;
        const detrended = greenValues.map(val => val - mean);
        const maxVal = Math.max(...detrended.map(Math.abs));
        const normalized = detrended.map(val => val / maxVal);
        const freq = getDominantFrequency(normalized, FRAME_RATE);
        heartRate = Math.round(freq * 60);
        if (heartRate < 40 || heartRate > 180) {
          throw new Error('Heart rate out of realistic range');
        }
      } catch (error) {
        console.error('PPG analysis failed:', error);
        heartRate = Math.floor(60 + (Math.random() * 40));
        isSimulated = true;
      }

      // Step 6: Facial analysis
      result.innerHTML = '<p class="fade-in">‚è≥ Analisando express√£o facial<span class="loading-dots"></span></p>';
      const captures = [];
      const audioCaptures = [];
      try {
        for (let i = 0; i < 2; i++) {
          context.drawImage(video, 0, 0, canvas.width, canvas.height);
          const imageBase64 = canvas.toDataURL('image/jpeg').split(',')[1];
          captures.push(imageBase64);

          const simulatedVoiceTone = 100 + Math.random() * 50; // Arbitrary range
          audioCaptures.push(simulatedVoiceTone);
          await new Promise(resolve => setTimeout(resolve, 100));
        }
      } catch (error) {
        console.error('Erro durante a an√°lise:', error);
        result.innerHTML = '<p class="fade-in">üö´ Erro durante a an√°lise. Tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
        speechOutput.textContent = ''; // Clear speech output
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
        }
        return;
      } finally {
        if (videoStream) {
          videoStream.getVideoTracks().forEach(track => track.stop());
          video.classList.add('hidden');
          placeholder.classList.remove('hidden');
          console.log('C√¢mera fechada ap√≥s an√°lise');
        }
        videoStream = null;
      }

      // Step 7: Process results with Face++ API
      let bestResult = null;
      let maxConfidence = 0;

      for (let i = 0; i < captures.length; i++) {
        const formData = new FormData();
        formData.append('api_key', apiKey);
        formData.append('api_secret', apiSecret);
        formData.append('image_base64', captures[i]);
        formData.append('return_attributes', 'emotion,age');

        try {
          const response = await fetch('https://api-us.faceplusplus.com/facepp/v3/detect', {
            method: 'POST',
            body: formData
          });
          const data = await response.json();
          console.log('Resposta da API Face++:', data);

          if (data.faces && data.faces.length > 0) {
            const face = data.faces[0];
            const emotion = face.attributes.emotion;
            const emotionsSorted = Object.entries(emotion).sort((a, b) => b[1] - a[1]);
            const confidence = emotionsSorted[0][1];
            if (confidence > maxConfidence) {
              maxConfidence = confidence;
              bestResult = { emotion, age: face.attributes.age.value, heartRate, voiceTone: audioCaptures[i], isSimulated };
            }
          }
        } catch (error) {
          console.error('Erro ao analisar captura:', error);
        }
      }

      // Step 8: Display diagnosis
      if (bestResult && maxConfidence >= 50) {
        const { emotion, age, heartRate, voiceTone, isSimulated } = bestResult;
        const emotionsSorted = Object.entries(emotion).sort((a, b) => b[1] - a[1]);
        const primaryEmotion = emotionsSorted[0][0];

        // Generate diagnosis using the new function
        const diag = generateDiagnosis(primaryEmotion, heartRate, age, isSimulated);

        // Build and display the diagnosis HTML
        const diagnosisHTML = `
          <h3 class="text-2xl font-bold mb-4 fade-in">Resultado do Diagn√≥stico</h3>
          <p class="fade-in"><strong>Emo√ß√£o Predominante:</strong> ${diag.primaryEmotionInPortuguese.charAt(0).toUpperCase() + diag.primaryEmotionInPortuguese.slice(1)}</p>
          <p class="fade-in"><strong>Idade Aparente:</strong> Entre ${diag.ageRangeMin} e ${diag.ageRangeMax} anos</p>
          <p class="fade-in mt-2">${diag.diagnosis}</p>
          <p class="fade-in mt-2"><strong>Poss√≠veis Gatilhos:</strong> ${diag.triggers}</p>
          <p class="fade-in mt-2"><strong>Sugest√£o:</strong> ${diag.suggestion}</p>
          <p class="fade-in mt-2"><strong>Plano Personalizado:</strong> ${diag.personalizedPlan}</p>
          ${diag.ctaButtons}
        `;

        result.innerHTML = diagnosisHTML;
        speechOutput.textContent = ''; // Clear the speech output after diagnosis
        speak(`Seu diagn√≥stico est√° pronto. Emo√ß√£o predominante: ${diag.primaryEmotionInPortuguese.charAt(0).toUpperCase() + diag.primaryEmotionInPortuguese.slice(1)}. ${diag.diagnosis}`);
      } else {
        result.innerHTML = '<p class="fade-in">üö´ N√£o foi poss√≠vel determinar uma emo√ß√£o com confian√ßa suficiente. Tente novamente.</p><div class="mt-6"><button onclick="captureAndAnalyze()" class="futuristic-btn text-white font-bold px-6 py-2 rounded-full text-sm shine">Tentar Novamente</button></div>';
        speechOutput.textContent = ''; // Clear the speech output
        speak('N√£o foi poss√≠vel determinar uma emo√ß√£o com confian√ßa suficiente. Tente novamente.');
      }
    }
  }
</script>
